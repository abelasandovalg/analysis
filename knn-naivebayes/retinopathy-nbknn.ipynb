{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetic Retinopathy Debrecen Dataset \n",
    "\n",
    "The goal for this analysis is to implement the Naive Bayes and KNN classifers to predict if patients have diabetic retinopathy or not. The dataset contains 1151 instances and 20 attributes (categorical and continuous) and can be found [here](http://archive.ics.uci.edu/ml/datasets/Diabetic+Retinopathy+Debrecen+Data+Set).\n",
    "\n",
    "### Set up Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1151 entries, 0 to 1150\n",
      "Data columns (total 20 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   quality     1151 non-null   int64  \n",
      " 1   prescreen   1151 non-null   int64  \n",
      " 2   ma2         1151 non-null   int64  \n",
      " 3   ma3         1151 non-null   int64  \n",
      " 4   ma4         1151 non-null   int64  \n",
      " 5   ma5         1151 non-null   int64  \n",
      " 6   ma6         1151 non-null   int64  \n",
      " 7   ma7         1151 non-null   int64  \n",
      " 8   exudate8    1151 non-null   float64\n",
      " 9   exudate9    1151 non-null   float64\n",
      " 10  exudate10   1151 non-null   float64\n",
      " 11  exudate11   1151 non-null   float64\n",
      " 12  exudate12   1151 non-null   float64\n",
      " 13  exudate13   1151 non-null   float64\n",
      " 14  exudate14   1151 non-null   float64\n",
      " 15  exudate15   1151 non-null   float64\n",
      " 16  eu_dist     1151 non-null   float64\n",
      " 17  diameter    1151 non-null   float64\n",
      " 18  amfm_class  1151 non-null   int64  \n",
      " 19  label       1151 non-null   int64  \n",
      "dtypes: float64(10), int64(10)\n",
      "memory usage: 180.0 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality</th>\n",
       "      <th>prescreen</th>\n",
       "      <th>ma2</th>\n",
       "      <th>ma3</th>\n",
       "      <th>ma4</th>\n",
       "      <th>ma5</th>\n",
       "      <th>ma6</th>\n",
       "      <th>ma7</th>\n",
       "      <th>exudate8</th>\n",
       "      <th>exudate9</th>\n",
       "      <th>exudate10</th>\n",
       "      <th>exudate11</th>\n",
       "      <th>exudate12</th>\n",
       "      <th>exudate13</th>\n",
       "      <th>exudate14</th>\n",
       "      <th>exudate15</th>\n",
       "      <th>eu_dist</th>\n",
       "      <th>diameter</th>\n",
       "      <th>amfm_class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>13.632699</td>\n",
       "      <td>7.576963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.507159</td>\n",
       "      <td>0.116663</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>54</td>\n",
       "      <td>49</td>\n",
       "      <td>25</td>\n",
       "      <td>52.972626</td>\n",
       "      <td>21.611270</td>\n",
       "      <td>8.145465</td>\n",
       "      <td>1.110534</td>\n",
       "      <td>0.041819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.517072</td>\n",
       "      <td>0.128556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>95</td>\n",
       "      <td>81</td>\n",
       "      <td>66</td>\n",
       "      <td>46</td>\n",
       "      <td>32</td>\n",
       "      <td>123.053484</td>\n",
       "      <td>70.571010</td>\n",
       "      <td>37.409891</td>\n",
       "      <td>19.937253</td>\n",
       "      <td>14.786668</td>\n",
       "      <td>6.114911</td>\n",
       "      <td>2.345740</td>\n",
       "      <td>1.002243</td>\n",
       "      <td>0.524461</td>\n",
       "      <td>0.134247</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>188.842000</td>\n",
       "      <td>109.620980</td>\n",
       "      <td>42.257684</td>\n",
       "      <td>4.227210</td>\n",
       "      <td>0.154783</td>\n",
       "      <td>0.023073</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.512692</td>\n",
       "      <td>0.093254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>42</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>28.504500</td>\n",
       "      <td>7.675472</td>\n",
       "      <td>1.572641</td>\n",
       "      <td>0.081556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.512511</td>\n",
       "      <td>0.135413</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>61</td>\n",
       "      <td>59</td>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "      <td>32.155976</td>\n",
       "      <td>17.636109</td>\n",
       "      <td>7.703571</td>\n",
       "      <td>1.426416</td>\n",
       "      <td>0.110909</td>\n",
       "      <td>0.009242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.515891</td>\n",
       "      <td>0.092424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>6.216010</td>\n",
       "      <td>1.987275</td>\n",
       "      <td>0.050837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.534695</td>\n",
       "      <td>0.095512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>112.316034</td>\n",
       "      <td>54.790166</td>\n",
       "      <td>16.021863</td>\n",
       "      <td>2.053484</td>\n",
       "      <td>0.317197</td>\n",
       "      <td>0.074175</td>\n",
       "      <td>0.036112</td>\n",
       "      <td>0.006832</td>\n",
       "      <td>0.522596</td>\n",
       "      <td>0.101503</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>97</td>\n",
       "      <td>88</td>\n",
       "      <td>77</td>\n",
       "      <td>66</td>\n",
       "      <td>43</td>\n",
       "      <td>20.800481</td>\n",
       "      <td>5.016614</td>\n",
       "      <td>1.363411</td>\n",
       "      <td>0.216976</td>\n",
       "      <td>0.009233</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.555425</td>\n",
       "      <td>0.112335</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>31</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>51.733169</td>\n",
       "      <td>20.030529</td>\n",
       "      <td>6.301271</td>\n",
       "      <td>0.873245</td>\n",
       "      <td>0.064914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483298</td>\n",
       "      <td>0.125191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      quality  prescreen  ma2  ma3  ma4  ma5  ma6  ma7    exudate8  \\\n",
       "875         1          0   34   34   34   33   31   28   13.632699   \n",
       "677         1          1   56   56   56   54   49   25   52.972626   \n",
       "16          1          1  105   95   81   66   46   32  123.053484   \n",
       "868         1          1   42   42   38   34   29   22  188.842000   \n",
       "157         1          1   47   45   45   42   36   26   28.504500   \n",
       "848         1          1   64   61   59   52   49   42   32.155976   \n",
       "249         1          1   32   32   32   30   27   20    6.216010   \n",
       "1045        1          1   24   24   21   20   17   10  112.316034   \n",
       "408         1          1  105   97   88   77   66   43   20.800481   \n",
       "795         1          1   34   34   34   31   26   19   51.733169   \n",
       "\n",
       "        exudate9  exudate10  exudate11  exudate12  exudate13  exudate14  \\\n",
       "875     7.576963   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "677    21.611270   8.145465   1.110534   0.041819   0.000000   0.000000   \n",
       "16     70.571010  37.409891  19.937253  14.786668   6.114911   2.345740   \n",
       "868   109.620980  42.257684   4.227210   0.154783   0.023073   0.001923   \n",
       "157     7.675472   1.572641   0.081556   0.000000   0.000000   0.000000   \n",
       "848    17.636109   7.703571   1.426416   0.110909   0.009242   0.000000   \n",
       "249     1.987275   0.050837   0.000000   0.000000   0.000000   0.000000   \n",
       "1045   54.790166  16.021863   2.053484   0.317197   0.074175   0.036112   \n",
       "408     5.016614   1.363411   0.216976   0.009233   0.001539   0.001539   \n",
       "795    20.030529   6.301271   0.873245   0.064914   0.000000   0.000000   \n",
       "\n",
       "      exudate15   eu_dist  diameter  amfm_class  label  \n",
       "875    0.000000  0.507159  0.116663           0      0  \n",
       "677    0.000000  0.517072  0.128556           0      0  \n",
       "16     1.002243  0.524461  0.134247           1      1  \n",
       "868    0.000961  0.512692  0.093254           1      1  \n",
       "157    0.000000  0.512511  0.135413           0      1  \n",
       "848    0.000000  0.515891  0.092424           0      0  \n",
       "249    0.000000  0.534695  0.095512           0      0  \n",
       "1045   0.006832  0.522596  0.101503           1      0  \n",
       "408    0.001539  0.555425  0.112335           0      1  \n",
       "795    0.000000  0.483298  0.125191           0      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list w column names \n",
    "col_names = []\n",
    "for i in range(20):\n",
    "    if i == 0:\n",
    "        col_names.append('quality')\n",
    "    if i == 1:\n",
    "        col_names.append('prescreen')\n",
    "    if i >= 2 and i <= 7:\n",
    "        col_names.append('ma' + str(i))\n",
    "    if i >= 8 and i <= 15:\n",
    "        col_names.append('exudate' + str(i))\n",
    "    if i == 16:\n",
    "        col_names.append('eu_dist')\n",
    "    if i == 17:\n",
    "        col_names.append('diameter')\n",
    "    if i == 18:\n",
    "        col_names.append('amfm_class')\n",
    "    if i == 19:\n",
    "        col_names.append('label')\n",
    "\n",
    "# read in data, add column names \n",
    "data = pd.read_csv(\"messidor_features.txt\", names = col_names)\n",
    "\n",
    "# preview data \n",
    "print(data.info())\n",
    "\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier \n",
    "\n",
    "The Naive Bayes (NB) classifier is based on the application of the Bayes' theory and assumes a strong independence between features. The Gaussian Naive Bayes algorithm estimates the features using a Gaussian distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1151,)\n",
      "(1151, 19)\n"
     ]
    }
   ],
   "source": [
    "# separate features and labels \n",
    "labels = data['label']\n",
    "features = data.drop(['label'], axis = 1) \n",
    "\n",
    "# check shape\n",
    "print(labels.shape)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5977286356821588\n"
     ]
    }
   ],
   "source": [
    "# create naive bayes \n",
    "gnb = GaussianNB()\n",
    "\n",
    "# get cv scores \n",
    "cv_scores = cross_val_score(gnb, features, labels, scoring='accuracy', cv=10)\n",
    "\n",
    "# print results \n",
    "print('accuracy:', cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model above came out to about 60% accurate. Now, let's look at the confusion matrix and classification report to asses how the model more in depth.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix and Classification Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      " [[502  38]\n",
      " [425 186]]\n",
      "\n",
      "classification report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.93      0.68       540\n",
      "           1       0.83      0.30      0.45       611\n",
      "\n",
      "    accuracy                           0.60      1151\n",
      "   macro avg       0.69      0.62      0.56      1151\n",
      "weighted avg       0.69      0.60      0.56      1151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# nb predictions \n",
    "predict = cross_val_predict(gnb, features, labels, cv=10) \n",
    "\n",
    "# confusion matrix \n",
    "cmat = confusion_matrix(labels, predict) \n",
    "\n",
    "# classification report\n",
    "nbreport = classification_report(labels, predict) \n",
    "\n",
    "# print results \n",
    "print('confusion matrix:\\n', cmat) \n",
    "print('\\nclassification report:\\n\\n', nbreport) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our confusion matrix and classification report, we can see the precision, recall, and F1-score. Precision represents the percent of our predictions that were correct and recall represents the percent of positive cases that we identified correctly. The F1-score summarizes both precision and recal into one metric and the closer the F1-score is to 1, the better the model is.\n",
    "\n",
    "#### Receiver Operating Characteristic (ROC) Curve\n",
    "\n",
    "Next, let's look at our Receiver Operating Characteristic (ROC) curve. Generating this curve is a great method to see how a predictive model can distinguish between true positives and true negatives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under Curve (AUC): 0.6211068702290077\n"
     ]
    }
   ],
   "source": [
    "# split data into train/test sets \n",
    "ltrain, ltest, ftrain, ftest = train_test_split(labels, features, test_size=0.20)\n",
    "\n",
    "# fit data to nb \n",
    "gnb.fit(ftrain, ltrain) \n",
    "\n",
    "# get probability estimates \n",
    "proba = gnb.predict_proba(ftest) \n",
    "\n",
    "# generate roc curve + auc \n",
    "fpr, tpr, thresh = roc_curve(ltest, proba[:, 1])\n",
    "auc = roc_auc_score(ltest, proba[:, 1])\n",
    "\n",
    "# plot ROC curve + print auc \n",
    "plt.plot([0,1],[0,1],'k--') #plot the diagonal line\n",
    "plt.plot(fpr, tpr, label='NB') #plot the ROC curve\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve Naive Bayes')\n",
    "plt.show()\n",
    "\n",
    "print('Area Under Curve (AUC):', auc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our reported AUC is around 0.62, which is considered not the best given that 0.5 denotes a bad classifier and 1 denotes a percet classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor (KNN) Classifier\n",
    "\n",
    "The KNN Classifier consists of a training stage and a test stage. In the training stage, the classifier takes the training data and memorizes it. In the test stage, the classifier compares the test data with the training data and returns maximum occuring label of the k-nearest data points. For this classifier, Euclidean distance will be used as the distance metric. \n",
    "\n",
    "For NB, the data did not need to be scaled, but it is critical for KNN since it is a distance based algorithm and the scale of the data affects it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create min max scaler \n",
    "scaler = MinMaxScaler([0, 1]) \n",
    "\n",
    "# standardize data\n",
    "features_scaled = scaler.fit_transform(features) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6351124437781108\n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.65      0.62       540\n",
      "           1       0.67      0.62      0.64       611\n",
      "\n",
      "    accuracy                           0.64      1151\n",
      "   macro avg       0.64      0.64      0.63      1151\n",
      "weighted avg       0.64      0.64      0.64      1151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create knn\n",
    "knn = KNeighborsClassifier(5) \n",
    "\n",
    "# fit data \n",
    "knn.fit(features_scaled, labels) \n",
    "\n",
    "# get cv scores\n",
    "cv_scores = cross_val_score(knn, features_scaled, labels, scoring='accuracy', cv=10) \n",
    "\n",
    "# knn predictions \n",
    "predict = cross_val_predict(knn, features_scaled, labels, cv=10)\n",
    "\n",
    "# get classification report \n",
    "knnreport = classification_report(labels, predict) \n",
    "\n",
    "# print results \n",
    "print('accuracy:', cv_scores.mean())\n",
    "print('\\nclassification report:\\n', knnreport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copmpred to the NB algorithm, KNN classification has much better scores overall. However, the F1-scores are still not the best. \n",
    "\n",
    "For the previous KNN model, k = 5 was used, but now lets use GridSearchCV to find the best parameters for the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'n_neighbors': 23}\n",
      "\n",
      "accuracy: 0.6602923538230885\n"
     ]
    }
   ],
   "source": [
    "# create knn \n",
    "knn = KNeighborsClassifier() \n",
    "\n",
    "# set params\n",
    "params = {'n_neighbors' : [x for x in range(1, 31)]}\n",
    "\n",
    "# create gridsearchcv\n",
    "grid_search = GridSearchCV(knn, params, cv=10, scoring='accuracy')\n",
    "\n",
    "# fit data \n",
    "grid_search.fit(features_scaled, labels) \n",
    "\n",
    "# print results \n",
    "print('best parameters:', grid_search.best_params_)\n",
    "print('\\naccuracy:', grid_search.best_score_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets run the model using n_neighbors = 23. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6602923538230885\n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.72      0.67       540\n",
      "           1       0.71      0.61      0.65       611\n",
      "\n",
      "    accuracy                           0.66      1151\n",
      "   macro avg       0.66      0.66      0.66      1151\n",
      "weighted avg       0.67      0.66      0.66      1151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create knn, k = 23\n",
    "knn = KNeighborsClassifier(23) \n",
    "\n",
    "# fit data \n",
    "knn.fit(features_scaled, labels) \n",
    "\n",
    "# get cv scores\n",
    "cv_scores = cross_val_score(knn, features_scaled, labels, scoring='accuracy', cv=10) \n",
    "\n",
    "# knn predictions \n",
    "predict = cross_val_predict(knn, features_scaled, labels, cv=10)\n",
    "\n",
    "# get classification report \n",
    "knnreport = classification_report(labels, predict) \n",
    "\n",
    "# print results \n",
    "print('accuracy:', cv_scores.mean())\n",
    "print('\\nclassification report:\\n', knnreport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take this model a step further, lets perform a nested cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6550749625187406\n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.74      0.67       540\n",
      "           1       0.71      0.58      0.64       611\n",
      "\n",
      "    accuracy                           0.66      1151\n",
      "   macro avg       0.66      0.66      0.65      1151\n",
      "weighted avg       0.67      0.66      0.65      1151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# nested cross validation \n",
    "nested_score = cross_val_score(grid_search, features_scaled, labels, cv=10, scoring='accuracy')\n",
    "\n",
    "# nested cv predictions \n",
    "predict = cross_val_predict(grid_search, features_scaled, labels, cv=10)\n",
    "\n",
    "# get classification report \n",
    "ncvreport = classification_report(labels, predict) \n",
    "\n",
    "# print results \n",
    "print('accuracy:', nested_score.mean())\n",
    "print('\\nclassification report:\\n', ncvreport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve our model, a PCA can be used to reduce the dimensionality of our model. KNN suffers from the curse of dimensionality and can perform poorly in higher dimensions.\n",
    "\n",
    "When doing cross-validation, a PCA needs to happen inside the cross-validation loop. To do this, a Pipeline needs to be created and passed into a cross-validation. Once created, it and the parameters can be passed into the GridSearchCV to find the best accuracy and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.6603124411820064\n",
      "\n",
      "best parameters: {'knn__n_neighbors': 23, 'pca__n_components': 13}\n"
     ]
    }
   ],
   "source": [
    "# create models \n",
    "pca = PCA()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# create pca and knn pipeline \n",
    "pipe = Pipeline(steps=[('pca', pca), ('knn', knn)])\n",
    "\n",
    "# set up parameters \n",
    "params = {\n",
    "    'pca__n_components': list(range(1, 19)), # range of components to keep \n",
    "    'knn__n_neighbors': list(range(1, 30)),  # range of k values \n",
    "    }\n",
    "\n",
    "# create gridsearchcv\n",
    "grid_search = GridSearchCV(pipe, params, cv=5, scoring='accuracy') \n",
    "\n",
    "# fit data \n",
    "grid_search.fit(features_scaled, labels)\n",
    "\n",
    "# print results \n",
    "print('best score:', grid_search.best_score_)\n",
    "print('\\nbest parameters:', grid_search.best_params_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with the best parameters, a GridSearchCV can be passed into another cross-validation loop to do a nested cross-validation and get the accuracy estimate as well as the classification report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6429098437794091\n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.72      0.65       540\n",
      "           1       0.70      0.58      0.63       611\n",
      "\n",
      "    accuracy                           0.64      1151\n",
      "   macro avg       0.65      0.65      0.64      1151\n",
      "weighted avg       0.65      0.64      0.64      1151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# nested cross validation \n",
    "nested_score = cross_val_score(grid_search, features_scaled, labels, cv=5, scoring='accuracy')\n",
    "\n",
    "# nested cv predictions \n",
    "predict = cross_val_predict(grid_search, features_scaled, labels, cv=5)\n",
    "\n",
    "# get classification report \n",
    "ncvreport = classification_report(labels, predict) \n",
    "\n",
    "# print results \n",
    "print('accuracy:', nested_score.mean())\n",
    "print('\\nclassification report:\\n', ncvreport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the accuracy did not improve much given the optimal parameters. In conclusion, the model is not accurate enough since it woul dbe wrong about 40% of the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio",
   "language": "python",
   "name": "portfolio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
