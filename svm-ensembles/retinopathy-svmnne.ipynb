{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetic Retinopathy Debrecen Dataset - SVM/Neural Network/Ensemble\n",
    "\n",
    "The goal for this analysis is to classify patients as either positive or negative for havving diabetic retinopathy. The classifiers for this analysis will be Support Vector Machine (SVM), Neural Network, and Ensemble classifiers. The dataset contains 1151 instances and 20 attributes (categorical and continuous) and can be found [here](http://archive.ics.uci.edu/ml/datasets/Diabetic+Retinopathy+Debrecen+Data+Set).\n",
    "\n",
    "### Set up Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score \n",
    "\n",
    "%matplotlib inline\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1151 entries, 0 to 1150\n",
      "Data columns (total 20 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   quality     1151 non-null   int64  \n",
      " 1   prescreen   1151 non-null   int64  \n",
      " 2   ma2         1151 non-null   int64  \n",
      " 3   ma3         1151 non-null   int64  \n",
      " 4   ma4         1151 non-null   int64  \n",
      " 5   ma5         1151 non-null   int64  \n",
      " 6   ma6         1151 non-null   int64  \n",
      " 7   ma7         1151 non-null   int64  \n",
      " 8   exudate8    1151 non-null   float64\n",
      " 9   exudate9    1151 non-null   float64\n",
      " 10  exudate10   1151 non-null   float64\n",
      " 11  exudate11   1151 non-null   float64\n",
      " 12  exudate12   1151 non-null   float64\n",
      " 13  exudate13   1151 non-null   float64\n",
      " 14  exudate14   1151 non-null   float64\n",
      " 15  exudate15   1151 non-null   float64\n",
      " 16  eu_dist     1151 non-null   float64\n",
      " 17  diameter    1151 non-null   float64\n",
      " 18  amfm_class  1151 non-null   int64  \n",
      " 19  label       1151 non-null   int64  \n",
      "dtypes: float64(10), int64(10)\n",
      "memory usage: 180.0 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality</th>\n",
       "      <th>prescreen</th>\n",
       "      <th>ma2</th>\n",
       "      <th>ma3</th>\n",
       "      <th>ma4</th>\n",
       "      <th>ma5</th>\n",
       "      <th>ma6</th>\n",
       "      <th>ma7</th>\n",
       "      <th>exudate8</th>\n",
       "      <th>exudate9</th>\n",
       "      <th>exudate10</th>\n",
       "      <th>exudate11</th>\n",
       "      <th>exudate12</th>\n",
       "      <th>exudate13</th>\n",
       "      <th>exudate14</th>\n",
       "      <th>exudate15</th>\n",
       "      <th>eu_dist</th>\n",
       "      <th>diameter</th>\n",
       "      <th>amfm_class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>47.326300</td>\n",
       "      <td>26.655198</td>\n",
       "      <td>12.243846</td>\n",
       "      <td>7.371068</td>\n",
       "      <td>5.069121</td>\n",
       "      <td>2.923860</td>\n",
       "      <td>1.354087</td>\n",
       "      <td>0.274686</td>\n",
       "      <td>0.488392</td>\n",
       "      <td>0.106393</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>114.678102</td>\n",
       "      <td>59.917325</td>\n",
       "      <td>25.885087</td>\n",
       "      <td>1.193682</td>\n",
       "      <td>0.015745</td>\n",
       "      <td>0.005904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.551971</td>\n",
       "      <td>0.085614</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>33</td>\n",
       "      <td>30.461898</td>\n",
       "      <td>13.966980</td>\n",
       "      <td>1.763305</td>\n",
       "      <td>0.137858</td>\n",
       "      <td>0.011221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.560632</td>\n",
       "      <td>0.129843</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>64</td>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>56</td>\n",
       "      <td>42</td>\n",
       "      <td>39.164755</td>\n",
       "      <td>9.526313</td>\n",
       "      <td>3.345879</td>\n",
       "      <td>0.245682</td>\n",
       "      <td>0.004607</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.481664</td>\n",
       "      <td>0.079847</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>56.855339</td>\n",
       "      <td>21.532559</td>\n",
       "      <td>4.982154</td>\n",
       "      <td>0.335777</td>\n",
       "      <td>0.003893</td>\n",
       "      <td>0.003893</td>\n",
       "      <td>0.003893</td>\n",
       "      <td>0.003893</td>\n",
       "      <td>0.561032</td>\n",
       "      <td>0.136257</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>31.004416</td>\n",
       "      <td>14.292234</td>\n",
       "      <td>0.994879</td>\n",
       "      <td>0.047469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.549666</td>\n",
       "      <td>0.133508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>50</td>\n",
       "      <td>22.276818</td>\n",
       "      <td>10.053161</td>\n",
       "      <td>0.868831</td>\n",
       "      <td>0.056869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.565797</td>\n",
       "      <td>0.127955</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "      <td>48</td>\n",
       "      <td>13.198181</td>\n",
       "      <td>5.947414</td>\n",
       "      <td>1.164862</td>\n",
       "      <td>0.101560</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>0.006155</td>\n",
       "      <td>0.003078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.507123</td>\n",
       "      <td>0.090788</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>159.901453</td>\n",
       "      <td>86.301094</td>\n",
       "      <td>26.082431</td>\n",
       "      <td>2.430988</td>\n",
       "      <td>0.072704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.531522</td>\n",
       "      <td>0.144385</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>66.900142</td>\n",
       "      <td>18.928429</td>\n",
       "      <td>7.771131</td>\n",
       "      <td>1.621016</td>\n",
       "      <td>0.155301</td>\n",
       "      <td>0.018271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.494315</td>\n",
       "      <td>0.112669</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      quality  prescreen  ma2  ma3  ma4  ma5  ma6  ma7    exudate8   exudate9  \\\n",
       "857         1          1   24   23   22   16   14    9   47.326300  26.655198   \n",
       "665         1          1   12   12    9    8    6    2  114.678102  59.917325   \n",
       "1148        1          0   49   48   48   45   43   33   30.461898  13.966980   \n",
       "502         1          1   66   64   63   62   56   42   39.164755   9.526313   \n",
       "801         1          1    8    8    8    7    7    5   56.855339  21.532559   \n",
       "174         1          0   13   13   13   12   11    6   31.004416  14.292234   \n",
       "1096        1          1   64   63   63   60   56   50   22.276818  10.053161   \n",
       "133         1          1   63   63   61   59   55   48   13.198181   5.947414   \n",
       "806         1          1   38   36   32   19   13    8  159.901453  86.301094   \n",
       "579         1          1   19   19   19   18   16   14   66.900142  18.928429   \n",
       "\n",
       "      exudate10  exudate11  exudate12  exudate13  exudate14  exudate15  \\\n",
       "857   12.243846   7.371068   5.069121   2.923860   1.354087   0.274686   \n",
       "665   25.885087   1.193682   0.015745   0.005904   0.000000   0.000000   \n",
       "1148   1.763305   0.137858   0.011221   0.000000   0.000000   0.000000   \n",
       "502    3.345879   0.245682   0.004607   0.001536   0.000000   0.000000   \n",
       "801    4.982154   0.335777   0.003893   0.003893   0.003893   0.003893   \n",
       "174    0.994879   0.047469   0.000000   0.000000   0.000000   0.000000   \n",
       "1096   0.868831   0.056869   0.000000   0.000000   0.000000   0.000000   \n",
       "133    1.164862   0.101560   0.020004   0.006155   0.003078   0.000000   \n",
       "806   26.082431   2.430988   0.072704   0.000000   0.000000   0.000000   \n",
       "579    7.771131   1.621016   0.155301   0.018271   0.000000   0.000000   \n",
       "\n",
       "       eu_dist  diameter  amfm_class  label  \n",
       "857   0.488392  0.106393           0      1  \n",
       "665   0.551971  0.085614           1      0  \n",
       "1148  0.560632  0.129843           0      0  \n",
       "502   0.481664  0.079847           0      1  \n",
       "801   0.561032  0.136257           1      0  \n",
       "174   0.549666  0.133508           0      0  \n",
       "1096  0.565797  0.127955           0      0  \n",
       "133   0.507123  0.090788           0      1  \n",
       "806   0.531522  0.144385           1      1  \n",
       "579   0.494315  0.112669           1      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list w column names \n",
    "col_names = []\n",
    "for i in range(20):\n",
    "    if i == 0:\n",
    "        col_names.append('quality')\n",
    "    if i == 1:\n",
    "        col_names.append('prescreen')\n",
    "    if i >= 2 and i <= 7:\n",
    "        col_names.append('ma' + str(i))\n",
    "    if i >= 8 and i <= 15:\n",
    "        col_names.append('exudate' + str(i))\n",
    "    if i == 16:\n",
    "        col_names.append('eu_dist')\n",
    "    if i == 17:\n",
    "        col_names.append('diameter')\n",
    "    if i == 18:\n",
    "        col_names.append('amfm_class')\n",
    "    if i == 19:\n",
    "        col_names.append('label')\n",
    "\n",
    "# read in data, add column names \n",
    "data = pd.read_csv(\"messidor_features.txt\", names = col_names)\n",
    "\n",
    "# preview data \n",
    "print(data.info())\n",
    "\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing \n",
    "\n",
    "Now that the data has been read it, the features and class labels need to be split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1151,)\n",
      "(1151, 19)\n"
     ]
    }
   ],
   "source": [
    "# separate features and labels \n",
    "labels = data['label']\n",
    "features = data.drop(['label'], axis = 1) \n",
    "\n",
    "# check shape\n",
    "print(labels.shape)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines (SVM)\n",
    "\n",
    "For Support Vector Machines (SVM), scaling the data is critical for the algorithm to work. To scale only the training data inside the cross-validation loop, a Pipeline needs to be used to pass into the cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7011368341803125\n"
     ]
    }
   ],
   "source": [
    "# create scaler \n",
    "scaler = StandardScaler() \n",
    "\n",
    "# create support vector classification \n",
    "svc = SVC() \n",
    "\n",
    "# create pipeline \n",
    "pipe = Pipeline(steps=[('scaler', scaler), ('svc', svc)]) \n",
    "\n",
    "# get cv scores\n",
    "cv_scores = cross_val_score(pipe, features, labels, cv=5)\n",
    "\n",
    "# print scores \n",
    "print('accuracy:', cv_scores.mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets see if the mode can improved by tuning the parameters, specifically the kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'svc__kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# set parameters to tune\n",
    "params = {'svc__kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "# create gridsearchcv + fit data \n",
    "grid_search = GridSearchCV(pipe, params, cv=5) \n",
    "grid_search.fit(features, labels) \n",
    "\n",
    "# print results \n",
    "print('best parameters:', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the grid search, the best parameter is a linear kernel. Now, lets pass the grid search into another cross validation loop to evaluate the accuracy of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7228646715603239\n"
     ]
    }
   ],
   "source": [
    "# get cv scores\n",
    "cv_scores = cross_val_score(grid_search, features, labels, cv=5)\n",
    "\n",
    "# print results \n",
    "print('accuracy:', cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By tuning the kernel parameter, the accuracy of the model slightly improved. Now, lets try finding the best 'C' paramter, which represents the cost for a misclassifciation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7454357236965933\n"
     ]
    }
   ],
   "source": [
    "# set parameters \n",
    "params = {\n",
    "    'svc__kernel': ['linear', 'rbf', 'poly', 'sigmoid'], \n",
    "    'svc__C': list(range(50, 101, 10))\n",
    "    }\n",
    "\n",
    "# create gridsearchCV + fit data \n",
    "grid_search = GridSearchCV(pipe, params, cv=5) \n",
    "grid_search.fit(features, labels) \n",
    "\n",
    "# get cv scores \n",
    "cv_scores = cross_val_score(grid_search, features, labels, cv=5)\n",
    "\n",
    "# print results \n",
    "print('accuracy:', cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the 'C' parameter has been tuned, the accuracy has increased. Lets try using a neural network to classify our data: \n",
    "\n",
    "### Neural Networks (NN) \n",
    "\n",
    "Neural Networks use a multi-layer perceptron (MLP) supervised learning algorithm. Much like the previous algorithm, MLPs are sensitive to features scaling which requires standardized data as input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7315189158667419\n"
     ]
    }
   ],
   "source": [
    "# create NN \n",
    "mlp = MLPClassifier() \n",
    "\n",
    "# create pipeline\n",
    "pipe = Pipeline(steps=[('scaler', scaler), ('mlp', mlp)]) \n",
    "\n",
    "# set parameters \n",
    "params = {\n",
    "    'mlp__hidden_layer_sizes': [(10, ), (20, ), (30, ), (40, ), (50, ), (60, )], \n",
    "    'mlp__activation': ['logistic', 'tanh', 'relu']\n",
    "    }\n",
    "\n",
    "# create gridsearchCV + fit data\n",
    "grid_search = GridSearchCV(pipe, params, cv=5) \n",
    "grid_search.fit(features, labels) \n",
    "\n",
    "# get cv scores\n",
    "cv_scores = cross_val_score(grid_search, features, labels, cv=5) \n",
    "\n",
    "# print accuracy \n",
    "print('accuracy:', cv_scores.mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, using a neural network as a classifier did not increase the accuracy of the model. \n",
    "\n",
    "### Ensemble Classifiers \n",
    "\n",
    "Ensemble classifiers combine the predictions of multiple base estimators to increase improve the accuracy of the predictions. There are several types of ensembles, but we will only be exploring Random Forests and AdaBoost.\n",
    "\n",
    "#### Random Forests\n",
    "\n",
    "Random forests are an kind of ensemble classifier where many estimators are built independently in parallel. This ensemble works by manipulating the input features of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6767588932806324\n"
     ]
    }
   ],
   "source": [
    "# create random forest classifier \n",
    "rfc = RandomForestClassifier() \n",
    "\n",
    "# set params \n",
    "params = { \n",
    "    'max_depth': list(range(35, 56)), \n",
    "    'min_samples_leaf': [8, 10, 12], \n",
    "    'max_features': ['sqrt', 'log2']\n",
    "    } \n",
    "\n",
    "# create gridsearchCV \n",
    "grid_search = GridSearchCV(rfc, params, cv=5) \n",
    "grid_search.fit(features, labels) \n",
    "\n",
    "# get cv scores \n",
    "cv_scores = cross_val_score(grid_search, features, labels, cv=5) \n",
    "\n",
    "# print accuracy \n",
    "print('accuracy:', cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost \n",
    "\n",
    "The other type of ensemble classifier, AdaBoost, creates an ensemble classifier called boosting where each of the classifiers are trained one-by-one where sampling on the training set depends on the performance of previous models, as opposed to Random Forests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6941501976284586\n"
     ]
    }
   ],
   "source": [
    "# create ada boost classifier \n",
    "ada = AdaBoostClassifier() \n",
    "\n",
    "# set params \n",
    "params = { 'n_estimators': list(range(50, 251, 25)) }\n",
    "\n",
    "# create gridsearchCV + fit data \n",
    "grid_search = GridSearchCV(ada, params, cv=5)\n",
    "grid_search.fit(features, labels) \n",
    "\n",
    "# get cv scores \n",
    "cv_scores = cross_val_score(grid_search, features, labels, cv=5)\n",
    "\n",
    "# print accuracy \n",
    "print('accuracy:', cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the AdaBoost did not perform the best overall, it did perform better than the random forest classifier. However, for the final model, lets use the Support Vector Machine classifier since it performed the best overall. \n",
    "\n",
    "### Final Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'svc__C': 70, 'svc__kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# create support vector classification \n",
    "svc = SVC() \n",
    "\n",
    "# create pipeline \n",
    "pipe = Pipeline(steps=[('scaler', scaler), ('svc', svc)]) \n",
    "\n",
    "# set parameters \n",
    "params = {\n",
    "    'svc__kernel': ['linear', 'rbf', 'poly', 'sigmoid'], \n",
    "    'svc__C': list(range(50, 101, 10))\n",
    "    }\n",
    "\n",
    "# create final model \n",
    "final_model = GridSearchCV(pipe, params, cv=5) \n",
    "final_model.fit(features, labels) \n",
    "\n",
    "# print best params \n",
    "print('best parameters:', final_model.best_params_) \n",
    "\n",
    "# dump final model \n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(final_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final model, the best parameters are shown above. Now, lets use the final model to classify a new record: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive for Diabetic Retinopathy\n"
     ]
    }
   ],
   "source": [
    "# new record to classify\n",
    "record = [ 0.05905386, 0.2982129, 0.68613149, 0.75078865, 0.87119216, 0.88615694,\n",
    "  0.93600623, 0.98369184, -0.47426472, -0.57642756, -0.53115361, -0.42789774,\n",
    " -0.21907738, -0.20090532, -0.21496782, -0.2080998, 0.06692373, -2.81681183,\n",
    " -0.7117194 ]\n",
    "\n",
    "# load the model \n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "if (loaded_model.predict([record]) == 1): \n",
    "    print('Positive for Diabetic Retinopathy')\n",
    "else: \n",
    "    print('Negative for Diabetic Retinopathy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio",
   "language": "python",
   "name": "portfolio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
